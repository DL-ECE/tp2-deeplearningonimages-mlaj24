# -*- coding: utf-8 -*-
"""convolution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zd9ua5VoJwDMY5MJkXEItKlV4ky3-x4o

# TP-2 Deep Learning on Images

## Clothes images classification using Fashion-MNIST dataset

In this notebook you will train your second and even third neural network. 

Feel free to look back at the Lecture-2 slides to complete the cells below.



All the dependencies are installed. Below we import them and will be using them in all our notebooks.
Please feel free to look arround and look at their API.
The student should be limited to these imports to complete this work.
"""

# Import the different module we will need in this notebook
import os

# To read and compute on Images: imageio [imageio doc](https://imageio.readthedocs.io/en/stable/)
# To create some plot and figures: matplolib [matplotlib doc](https://matplotlib.org/)
# To do computation on matrix and vectors: numpy [numpy doc](https://numpy.org/)
import imageio
import matplotlib.pyplot as plt
import numpy as np

# To do computation on matrix and vectors and automatic differenciation: pytorch [torch doc](https://pytorch.org/docs/stable/index.html)
import torch
import torch.nn as nn
import torch.optim as optim
from torch.nn import functional as F
from torch.utils.data import DataLoader

# To do some computation on images with pytorch direclty on the GPU [torchvision doc](https://pytorch.org/vision)
from torchvision import transforms
from torchvision.datasets import MNIST, FashionMNIST
import random
import tqdm.notebook as tq

# To get the same data as TP1 
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
# enable tpu computation
# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py
# !python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev

# In order to have some reproducable results and easier debugging 
# we fix the seed of random.
random.seed(1342)
np.random.seed(1342)
torch.manual_seed(1342)
torch.cuda.manual_seed_all(1342)

import builtins as __builtin__
def print(*args, **kwargs):
    """My custom print() function."""
    return __builtin__.print(*args, **kwargs, end='\n\n')

"""## Refresh on numpy and images"""

# Let's do again basics of numpy 
mat_numpy = np.arange(15).reshape(3, 5)
print(mat_numpy) # Create a vector from 0 to 14 and reshape it into a Matrix 3X5

print(mat_numpy.shape) # Return the size of the matrix (3, 5)

print(mat_numpy[0]) # Return the first row of the matrix 

print(mat_numpy[0,3]) # Return first row and 4th column  element 

# Also interesting with higher dimension 
# Below can be though of 2 3X4 matrix 
tensor = np.zeros((2,3,4))   # Create an tensor of shape [2,2,2] of all zeros
print(tensor)                # Prints [[[0. 0. 0. 0.]
                             #          [0. 0. 0. 0.]
                             #          [0. 0. 0. 0.]]
                             #        [[0. 0. 0. 0.]
                             #         [0. 0. 0. 0.]
                             #         [0. 0. 0. 0.]]]

"""Now it's your turn create a function that return a tensor of shape 
n_rowsxn_columsxn_channels that contains a default value every where
"""

def build_image_like_tensor(n_rows:int, n_colums: int, n_channels:int, default_value: int)-> np.ndarray:
  """Create a tensor of 3 dimension. 
     It should have a shape similar to (n_rows, n_colums, n_channels)
     It should be containing the default value set by default_value
  """
  tensor = np.full((n_rows, n_colums, n_channels), default_value)
  # YOUR CODE HERE
  return tensor

# Create 3 different tensors with the above function containing different value between [0,255]
# Uncomment the 3 line below and complete with your answer 

white_like = build_image_like_tensor(6,8,7,0)
gray_like = build_image_like_tensor(5,3,4, 1)
black_like = build_image_like_tensor(10, 23, 21, 1)

# Each of the tensor that you have created can be seen as an image. Use here is the way to display it using matplotlib imshow:
def plot_one_tensor(image_tensor: np.array):
    """Function to plot the image tensor"""
    plt.imshow(image_tensor.reshape(image_tensor.shape[0], image_tensor.shape[1]*image_tensor.shape[2]), cmap='gray')

plot_one_tensor(white_like)

plot_one_tensor(gray_like)

plot_one_tensor(black_like)

"""We saw that an digital image is the combination of a 3 channel tensor RGB. 
Each channel represent respectively the R red componant, G greed componant, B blue componant.
"""

# Create again 3 image tensors with your function
# Then change them to be representing a red, a green, a blue image
# Uncomment the 3 line below and complete with your answer 


red_like = build_image_like_tensor(5,5,5,255)
green_like = build_image_like_tensor(2,2,2,0)
blue_like = build_image_like_tensor(3,2,4,0)

plot_one_tensor(red_like)

plot_one_tensor(green_like)

plot_one_tensor(blue_like)

"""## What Pytorch can do

*   Similar functions to Numpy on GPU
*   Calculate automatically gradient on the neural network
*   Some neural networks layers are already coded : dense, convolution, pooling, etc
*   Calculate automatically the weights update
*   Provide optimizer to compute gradient descent
"""

mat_torch = torch.arange(15).reshape(3,5)

print(mat_torch) # Create a vector from 0 to 14 and reshape it into a Matrix 3X5
print(mat_torch.shape) # Return the size of the matrix (3, 5)
print(mat_torch[0]) # Return the first row of the matrix 
print(mat_torch[0,3]) # Return first row and 4th column element 
# This was easy but everything was on the CPU so it's the same as Numpy 
# To do computation on the GPU (graphic card calculation can be 50x faster)

# What is the GPU on this machine ? 
# !nvidia-smi
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

mat_torch = torch.arange(15, device=device).reshape(3,5)
print(mat_torch) # Create a vector from 0 to 14 and reshape it into a Matrix 3X5
print(mat_torch.shape) # Return the size of the matrix (3, 5)
print(mat_torch[0]) # Return the first row of the matrix 
print(mat_torch[0,3]) # Return first row and 4th column element

"""Let's say we want a faster sigmoid and softmax. 
We can use the same function from TP-1
"""

def normalize_tensor(input_tensor: torch.Tensor) -> torch.Tensor:
    """Apply a normalization to the tensor"""
    # YOUR CODE HERE
    return (torch.from_numpy(input_tensor)/255).float()
   

def sigmoid(input_tensor: torch.Tensor) -> torch.Tensor:
    """Apply a sigmoid to the input Tensor"""
    # YOUR CODE HERE
    return 1/(1+torch.exp(-input_tensor))

def softmax(input_tensor: torch.Tensor)-> torch.Tensor:
    """Apply a softmax to the input tensor"""
    # YOUR CODE HERE 
    return torch.exp(input_tensor)/torch.sum(torch.exp(input_tensor), axis=1).reshape(-1,1)

def target_to_one_hot(targets: torch.Tensor, num_classes=10) -> torch.Tensor:
    """Create the one hot representation of the target""" 
    # YOUR CODE HERE 
    if targets.dtype.type != np.int :
        target = torch.from_numpy(targets.astype(int))
    else :
        target = torch.from_numpy(targets)
    pass

    return torch.eye(torch.max(target)+1)[target]

# However as mention above pytorch already has some built-ins function 

# sigmoid function [sigmoid doc](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html?highlight=sigmoid#torch.nn.Sigmoid)
# softmax function [softmax doc](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html?highlight=softmax#torch.nn.Softmax)

mat_torch = torch.arange(15, dtype=torch.float64, device=device).reshape(3,5)
# Uncomment the line bellow to check if your implementation is correct

assert torch.allclose(sigmoid(mat_torch), torch.sigmoid(mat_torch))
print(sigmoid(mat_torch))
print(torch.sigmoid(mat_torch))

assert torch.allclose(softmax(mat_torch), torch.softmax(mat_torch, dim=1))
print(softmax(mat_torch))
print(torch.softmax(mat_torch, dim=1))

"""## Transforming our Neural network from TP1"""

if __name__ == "__main__":
    # Downloading again the same MNIST dataset 

    mnist_data, mnist_target = fetch_openml('mnist_784', version=1, return_X_y=True)
    X_train, X_test, y_train, y_test = train_test_split(mnist_data, mnist_target, test_size=0.33, random_state=1342)
    # Change the input data to be normalize and target data to be correctly encoded 

    X_train = normalize_tensor(X_train)

    X_test = normalize_tensor(X_test)
   
    y_train = target_to_one_hot(y_train)

    y_test = target_to_one_hot(y_test)

"""Your remember the famous `class FFNN` from **TP1** ?? 

Here we will create the same version but with pytorch and we will see the power of this framework. 

Auto calculation of the backward pass and auto update of the weights ðŸŽ‰

In pytorch a dense layer similar to our `Class Layer` is a called **Linear Layer**

[linear layer documentation] -> https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear
"""

class FFNN(nn.Module):
    def __init__(self, config, device, minibatch_size=100, learning_rate=0.01, momentum=0):
        super().__init__()
        self.layers = []
        self.nlayers = len(config)
        self.minibatch_size = minibatch_size
        self.learning_rate = learning_rate
        self.momentum = momentum
        self.device = device 

        # We use the built-in activation functions
        # TODO: Maybe try with another activation function ! 
        self.activation = torch.nn.Sigmoid()
        # self.activation = torch.nn.ReLU()


        self.last_activation = torch.nn.Softmax(dim=1)

        # First difference we don't need a special Input layer ðŸ˜ƒ
        # Second one we can declare them more easely
        for i in range(1,len(config)):
          layer = nn.Linear(config[i-1], config[i])
          self.layers.append(layer)
          self.layers.append(self.activation)

        self.layers[-1]= self.last_activation
        self.model = nn.Sequential(*self.layers)

        # We use the built-in function to compute the loss
        # TODO: Maybe try with another loss function ! 
        # self.loss_function = torch.nn.MSELoss()
        self.loss_function = torch.nn.CrossEntropyLoss()

        # We use the built-in function to update the model weights
        self.optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=self.momentum)

    # Here we see the power of Pytorch
    # The forward is just giving the input to our model
    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:
      y_pred = self.model(input_tensor)
      return y_pred

    def compute_loss(self, y_pred: torch.Tensor, y_true) -> torch.Tensor:
        y_true = torch.argmax(y_true, dim=1)
        loss = self.loss_function(y_pred.float(), y_true)
        # looking at what the loss looks like
        print(loss)
        return loss

    # Even more powerful no need to code all the derivative of the different function
    def backward_pass(self, loss: torch.tensor) -> None:
        loss.backward()
        return

    # The previoulsy hard function to update the weight become also easy
    def update_all_weights(self):
      # Using pytorch
      self.optimizer.step()


    def get_error(self, y_pred, y_true) -> float:
      y_pred = torch.argmax(y_pred, dim=1)
      y_true = torch.argmax(y_true, dim=1)
      return (y_pred == y_true).float().mean()

    def get_test_error(self, X_test, y_test) -> float:
      nbatch = X_test.shape[0]
      error_sum = 0.0
      for i in range(0, nbatch):
          X_batch = X_test[i,:,:].reshape(self.minibatch_size, -1)
          y_batch = y_test[i,:,:].reshape(self.minibatch_size, -1)
          y_pred = self.model(X_batch)
          error_sum += self.get_error(y_pred, y_batch)
      return error_sum / nbatch

    def train(self, n_epochs: int, X_train: torch.Tensor, y_train: torch.Tensor, X_test: torch.Tensor, y_test: torch.Tensor):
      X_train = X_train.reshape(-1, self.minibatch_size, 784).to(self.device)
      y_train = y_train.reshape(-1, self.minibatch_size, 10).to(self.device)

      X_test = X_test.reshape(-1, self.minibatch_size, 784).to(self.device)
      y_test = y_test.reshape(-1, self.minibatch_size, 10).to(self.device)

      
      self.model = self.model.to(device)
      nbatch = X_train.shape[0]
      error_test = 0.0
      for epoch in range(n_epochs): 
        error_sum_train = 0.0
        for i in range(0, nbatch):
          X_batch = X_train[i,:, :]
          y_batch = y_train[i,:, :]
          # In order to have the correct derivative we remove the one from before 
          self.optimizer.zero_grad()
          # Then we do a pass forward 
          y_pred = self.model(X_batch)
          # We compute the loss 
          loss = self.compute_loss(y_pred, y_batch)
          # And calculate the backward pass
          self.backward_pass(loss=loss)
          # To finally update the weights using stochastic gradient descent 
          self.update_all_weights()
          error_sum_train += self.get_error(y_pred, y_batch)
        error_test = self.get_test_error(X_test, y_test)
        
        print(f"Training Loss: {loss:.3f}, Training accuracy: {error_sum_train / nbatch:.3f}, Test accuracy: {error_test:.3f}")
      return loss, error_test

if __name__ == "__main__":
    minibatch_size = 28
    nepoch = 50
    learning_rate = 0.1
    ffnn = FFNN(config=[784, 256, 128, 10], device=device, minibatch_size=minibatch_size, learning_rate=learning_rate)
    print(ffnn)
    loss, err = ffnn.train(nepoch, X_train, y_train, X_test, y_test)

"""In pytorch a very convinient way to load data in batch si to use the data loader. 

Let's update the class to use it, we are also going to use dataset available in pytorch vision.
"""

class FFNNModel(nn.Module):
    def __init__(self, classes=10):
        super().__init__()
        # not the best model...
        self.l1 = torch.nn.Linear(784, 256)
        self.l2 = torch.nn.Linear(256, 128)
        self.l3 = torch.nn.Linear(128, classes)
        self.activation = torch.nn.ReLU()
        self.last_activation = torch.nn.Softmax(dim=1)

    def forward(self, input):
        input = input.reshape(input.size(0), -1)
        x = self.l1(input)
        x = self.activation(x)
        x = self.l2(x)
        x = self.activation(x)
        x = self.l3(x)
        y = self.last_activation(x)
        return y

def train_one_epoch(model, device, data_loader, optimizer):
    train_loss = 0
    correct = 0
    for num, (data, target) in tq.tqdm(enumerate(data_loader), total=len(data_loader.dataset)/data_loader.batch_size):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)

        loss = F.cross_entropy(output, target)
        loss.backward()
        train_loss += loss.item()
        optimizer.step()

        prediction = output.argmax(dim=1)
        correct += torch.sum(prediction.eq(target)).item()

    result = {'loss': train_loss / len(data_loader.dataset),
              'accuracy': correct / len(data_loader.dataset)
              }
    return result   
 
def evaluation(model, device, data_loader):
    eval_loss = 0
    correct = 0

    for num, (data, target) in tq.tqdm(enumerate(data_loader), total=len(data_loader.dataset)/data_loader.batch_size):
        data, target = data.to(device), target.to(device)
        output = model(data)
        eval_loss += F.cross_entropy(output, target).item()
        prediction = output.argmax(dim=1)
        correct += torch.sum(prediction.eq(target)).item()
    result = {'loss': eval_loss / len(data_loader.dataset),
              'accuracy': correct / len(data_loader.dataset)
              }
    return result

if __name__ == "__main__":
    
    # Network Hyperparameters 
    minibatch_size = 28
    nepoch = 10
    learning_rate = 0.1
    momentum = 0 
    model = FFNNModel()
    model.to(device)
    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)

    # Retrieve the data with the pytorch dataloader 
    mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())
    mnist_train = DataLoader(mnist_train, batch_size=32, num_workers=4, pin_memory=True)
    mnist_val = MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor())
    mnist_val = DataLoader(mnist_val, batch_size=32, num_workers=4,  pin_memory=True)

    # Train for an number of epoch 
    for epoch in range(nepoch):
      print(f"training Epoch: {epoch}")
      if epoch > 0:
        train_result = train_one_epoch(model, device, mnist_train, optimizer)
        print(f"Result Training dataset {train_result}")

      eval_result = evaluation(model, device, mnist_val)
      print(f"Result Test dataset {eval_result}")

"""# Part 1: What is a convolution ?

In this section you will implement 2D convolution operation using:

Starting with a simple example and manual computation like in Lecture 2

1) Introduction: manual computation

- you have as input an image of 5x5 pixels

$I = \begin{bmatrix}I_{1, 1} & ... & I_{1, 5} \\ \vdots & \ddots & \vdots \\ I_{5, 1}& ... & I_{5,5}\end{bmatrix}$

Your task is to compute the result of a convolution operation between this image and a 3x3 kernel

$ K = \begin{bmatrix}a & b & c \\d & e & f \\ g& h& i\end{bmatrix}$

We are considering padding with 0 and using the SAME convolution. 
Meaning that arround the I matrix consider there is the value 0.

Tips: the result of the convolution is a 5x5 matrix
"""

I = np.array([[252,  49, 113,  11, 137],
                [ 18, 237, 163, 119,  53],
                [ 90,  89, 178,  75, 247],
                [209, 216,  48, 135, 232],
                [229, 53, 107, 106, 222]])
print(f"I =")
print(I)

K_0 = np.array([[0, 1, 0], [0, 0, 0], [0, 0, 0]])
print(f"K_0 =")
print(K_0)

K_1 = np.array([[1, 1, 1], [0, 5, 0], [-1, -1, -1]])
print(f"K_1 =")
print(K_1)

"""What is the result of convolution of $ I_0 \ast K_0 $"""

# put your answer here

I_0 = np.zeros([I.shape[0]+2, I.shape[1]+2])
I_0[1:I_0.shape[0]-1, 1:I_0.shape[1]-1] = I
R_0 = np.zeros([I.shape[0], I.shape[1]])

for i in range(0,R_0.shape[0]):
  for j in range(0,R_0.shape[1]):
      R_0[i,j] = np.sum(I_0[i:i+K_0.shape[0],j:j+K_0.shape[1]]*K_0)

print(R_0)

"""What is the result of convolution of $ I_0 \ast K_1 $"""

# put your answer here

I_1 = np.zeros([I.shape[0]+2, I.shape[1]+2])
I_1[1:I_1.shape[0]-1, 1:I_1.shape[1]-1] = I
R_1 = np.zeros([I.shape[0], I.shape[1]])

for i in range(0,R_1.shape[0]):
  for j in range(0,R_1.shape[1]):
      R_1[i,j] = np.sum(I_1[i:i+K_1.shape[0],j:j+K_1.shape[1]]*K_1)

print(R_1)

"""## 2) Computation using __numpy__

Now using the numpy implement the convolution operation.
"""

def convolution_forward_numpy(image, kernel):
    # YOUR CODE HERE 
    x_out = image.shape[0]
    y_out = image.shape[1]
    if (len(image.shape)==3) :
      z_out = image.shape[2]
    elif (len(image.shape)<3) :
      z_out = 1
    pass
    image_n = np.zeros((x_out+2, y_out+2, z_out))
    image_n[1:x_out+1, 1:y_out+1, :] = image.reshape(image.shape[0], image.shape[1], z_out)
    out=np.zeros((x_out, y_out, z_out))

    
    for k in range(0, z_out):
      for i in range(0, x_out):
        for j in range(0, y_out):
            out[i,j,k] = np.sum(image_n[i:i+kernel.shape[0], j:j+kernel.shape[1], k]*kernel)

              
    if (z_out==1) :
      out = out.reshape(x_out, y_out)
    return out

"""Test your implementation on the two previous example and compare the results to the result manually computed."""

assert np.array_equal(convolution_forward_numpy(I,K_0),R_0)
assert np.array_equal(convolution_forward_numpy(I,K_1),R_1)

"""Display the result image of the convolution"""

# Load image from url, you can use an other image if you want
image_url = "https://upload.wikimedia.org/wikipedia/commons/4/4f/ECE_Paris_Lyon.jpg"
image = imageio.imread(image_url)


# simple function to display image
def display_image(img):
    plt.imshow(img)

# display the image
display_image(image)

# Do the convolution operation and display the resulting image

# YOUR CODE HERE
kernel = np.array([[9,4,2],[7,6,4],[0,3,4]])
output_image = convolution_forward_numpy(image, kernel) 
display_image(output_image)

"""## 3) Computation using __pytorch__

Now let's use pytorch convolution layer to do the forward pass. Use the documentation available at: https://pytorch.org/docs/stable/nn.html
"""

def convolution_forward_torch(image, kernel):
    # YOUR CODE HERE 
    image_t = torch.from_numpy(image)
   
    image_n = torch.ones((image_t.shape[0]+2, image_t.shape[1]+2))
    image_n[1:image_n.shape[0]-1, 1:image_n.shape[1]-1] = image_t
    kernel_t = torch.zeros(kernel.shape[0], kernel.shape[1], 1)
    kernel_t[:,:,0]=torch.from_numpy(kernel)
    out = F.conv2d(image_n.view(1,1,image_n.shape[0], image_n.shape[1]), kernel_t.view(1,1,kernel.shape[0],kernel.shape[1]))
    return out.reshape((out.shape[-2], out.shape[-1]))

"""In pytorch you can also access other layer like convolution2D, pooling layers, for example in the following cell use the __torch.nn.MaxPool2d__ to redduce the image size."""

reduce = torch.nn.MaxPool2d(kernel_size=2)

reduced = reduce(torch.from_numpy(output_image))

"""# Part 2: Using convolution neural network to recognize digits

In this section you will implement 2D convolution neural network and train it on fashion mnist dataset

https://github.com/zalandoresearch/fashion-mnist


![Image of fashion mnist](https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png)

##  First let's look at the data.
"""

if __name__ == "__main__" :

  fmnist_train = FashionMNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())
  fmnist_train = DataLoader(fmnist_train, batch_size=32, num_workers=4, pin_memory=True)
  fmnist_val = FashionMNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor())
  fmnist_val = DataLoader(fmnist_val, batch_size=32, num_workers=4,  pin_memory=True)

"""Display the 10 image from train set and 10 images from validation set, print their ground truth"""

def display_10_images(dataset):
    # YOUR CODE HERE 
    for i in range(0, 10) :
      plt.figure
      display_image(dataset[i])

display_10_images(fmnist_train.dataset.data)

"""What is the shape of each images
How many images do we have
What are the different classes
"""

def fashion_mnist_dataset_answer():
    shape = [28,28]  # replace None with the value you found
    number_of_images_in_train_set = fmnist_train.dataset.data.shape[0]
    number_of_images_in_test_set = fmnist_val.dataset.data.shape[0]
    number_of_classes = len(fmnist_train.dataset.classes)
    return {'shape': shape, 'nb_in_train_set': number_of_images_in_train_set, 'nb_in_test_set': number_of_images_in_test_set, 'number_of_classes': number_of_classes}

fashion_mnist_dataset_answer()

# Plot an image and the target

"""## Create a convolutional neural network

Now it's your turn to create a convolutional neural network and to train your model on the fashion mnist dataset.

Classical machine learning approach manage to get a 89% accuracy on fashion mnist, your objective is to use deep learning (and convolution neural network) to get more than 90%

You can first start with this simple convolution network and improve it by adding/modifying the layers used:

```
convolutional layer 3x3
convolutional layer 3x3
max-pooling
convolutional layer 3x3
convolutional layer 3x3
max-pooling
flatten
fully-connected layer (dense layer)
fully-connected layer (dense layer)
fully-connected layer (dense layer)
Softmax
```
"""

class CNNModel(nn.Module):
    def __init__(self, classes=10):
        super().__init__()
        # YOUR CODE HERE 
        self.conv1 = nn.Sequential(
            torch.nn.Conv2d(kernel_size=3), # 784
            torch.nn.Conv2d(kernel_size=3), # 784
            torch.nn.MaxPool2D(kernel_size=2), # 392
            torch.nn.Conv2d(kernel_size=3), # 392
            torch.nn.Conv2d(kernel_size=3), # 392
            torch.nn.MaxPool2D(kernel_size=2), # 191
            torch.nn.Flatten(),
            torch.nn.Linear(191, 100000),
            torch.nn.Linear(100000, 1000),
            torch.nn.Linear(1000, classes),
            )

    def forward(self, input):
        x = self.conv1(input)
        # YOUR CODE HERE 
        y = softmax(x)
        return y

def train_one_epoch(model, device, data_loader, optimizer):
    train_loss = 0
    correct = 0
    for num, (data, target) in tq.tqdm(enumerate(data_loader), total=len(data_loader.dataset)/data_loader.batch_size):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        
        # YOUR CODE HERE 
        loss = F.cross_entropy(output, target)
        loss.backward()
        train_loss += loss.item()
        optimizer.step()

        prediction = output.argmax(dim=1)
        correct += torch.sum(prediction.eq(target)).item()

    result = {'loss': train_loss / len(data_loader.dataset),
              'accuracy': correct / len(data_loader.dataset)
              }
    return result   
 
def evaluation(model, device, data_loader):
    eval_loss = 0
    correct = 0

    for num, (data, target) in tq.tqdm(enumerate(data_loader), total=len(data_loader.dataset)/data_loader.batch_size):
        data, target = data.to(device), target.to(device)
        output = model(data)
        
        # YOUR CODE HERE 
        eval_loss = F.cross_entropy(output, target).item()
        prediction = output.argmax(dim=1)
        correct += torch.sum(prediction.eq(target)).item()
    result = {'loss': eval_loss / len(data_loader.dataset),
              'accuracy': correct / len(data_loader.dataset)
              }
    return result
    
if __name__ == "__main__":
    
    # Network Hyperparameters 
    # YOUR CODE HERE 
    minibatch_size = 20
    nepoch = 15
    learning_rate = 0.1
    momentum = 0


    model = FFNNModel()
    model.to(device)

    # YOUR CODE HERE 
    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)

    # Train for an number of epoch 
    for epoch in range(nepoch):
      print(f"training Epoch: {epoch}")
      if epoch > 0:
        train_result = train_one_epoch(model, device, mnist_train, optimizer)
        print(f"Result Training dataset {train_result}")

      eval_result = evaluation(model, device, mnist_val)
      print(f"Result Test dataset {eval_result}")

"""## Open Analysis
(Same as TP 1 please write a short description of your experiment)

My model depends of the same hypermaremeters than in TP1 : the batch_size, the learning_rate and a number of epochs

I also take in consideration the momentum, which is a coefficient (between 0 and 1) that, if not null, accumulates the gradient of the past steps to determine the gradient of the current step. The value of the momentum is equal to the percentage of past gradients to consider in next calculations.

The experiment has been made with a set of 70000 images divided in 10 categories or classes from Fashion MNIST - Database. I trained a CNN Model able to recognize the right product category of an image. 86% of the data have been used for training, and the other 14% have been used to test the model after traning. The objective was to have a minimum of 90% accuracy for both training and testing, enough to be representative of reality and not enough to match the training set too much.

After multiple tries with hyperparameters values, I decided to end my experiment with a batch_size of 20, a learning rate of 0.1, 15 epochs and a 0 momentum (nearly the same hyperparameters of TP1, only the learning rate changes). The sequence of my model remained the same than advised, starting with 2 successive subsequences of 2 3x3 convolution layers and one 2D Max-Pooling layer, then a Flatten layer and 3 Fully-Connected layers.

For all epochs, a certain number of batches of 32 images each are treated. 1875 batches for traning and 313 batches for testing. 

The first epoch (=0) consists only of a test that ends with poor accuracy (around 10% or more). Logical as the traning hasn't started yet. It is only from the first epoch with actual model training (=1) that we can notice an accuracy skyrocketting for both traning and test, complement of a loss plumetting. Accuracies tend to go up fast, then slower and slower as we arrive to a ceiling near 97% or 98%, awesome numbers when it comes to describing the quality of a model. At the end, training accuracy was around 98% and test accuracy was around 97%, which is way more than enough to consider the objective of this experiment complete.

Like in TP1, when raising the number of epochs, accuracies can only go up at the end. 

However, unlike in TP1, the choosing of the learning rate is more indulgent. It is due to the structure of the model, which isn't a classic feed-forward ANN, but a CNN, and CNN are built much better to recognize images than ANN, as they automatically learn the right filters to extract the right features to recognize an image. In TP1, choosing a learning rate of 0.1 made the training and testing more inconsistent (sometimes it went up, sometimes it went down), which meant the learning wasn't fit to minimize the error effectively. The model needed a smaller learning rate. This is not the case in this experiment as a learning rate of 0.1 helped in the fast raising of accuracy, while keeping a consistent trend for the evolution of accuracies, both always going up, just not at the same rate.

# BONUS 

Use some already trained CNN to segment YOUR image. 

In the cell below your can load a image to the notebook and use the given network to have the segmentation mask and plot it.
"""

if __name__ == "__main__" :
    
    # TODO HERE: Upload an image to the notebook in the navigation bar on the left
    # `File` `Load File`and load an image to the notebook. 
    
    filename = "" 
    # Loading a already trained network in pytorch 
    model = torch.hub.load('pytorch/vision:v0.6.0', 'deeplabv3_resnet101', pretrained=True)
    model.eval()

    from PIL import Image
    from torchvision import transforms

    input_image = Image.open(filename)
    preprocess = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    input_tensor = preprocess(input_image)
    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model

    # move the input and model to GPU for speed if available
    if torch.cuda.is_available():
        input_batch = input_batch.to('cuda')
        model.to('cuda')

    with torch.no_grad():
        output = model(input_batch)['out'][0]
    output_predictions = output.argmax(0)

